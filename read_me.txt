# ðŸ¢ Business Intelligence Platform - Setup Guide

## ðŸ“‹ Overview

This is a professional AI-powered Business Intelligence Platform designed for regulatory mapping error analysis. The tool helps business analysts identify and resolve data mapping issues using advanced language models with contextual document analysis.

### âœ¨ Key Features
- **AI-Powered Analysis**: Multiple LLM models (Llama 3, Mistral, Gemma 2, CodeLlama)
- **Document Context**: RAG (Regulatory Guidelines) & CAG (Company Procedures) 
- **SQL Analytics**: Natural language to SQL conversion with database analysis
- **Corporate Branding**: Fully customizable enterprise interface
- **Dark/Light Mode**: Professional UI with theme switching
- **Audit Logging**: Enterprise-grade compliance tracking

---

## ðŸš€ Quick Start (Automated Installation)

### Option 1: One-Click Setup Script
```bash
# Download and run the automated installer
python install_and_run.py
```

### Option 2: Corporate Setup Script (Recommended for Enterprise)
```bash
# Make the setup script executable
chmod +x setup_corporate_env.sh

# Run the corporate setup (includes branding configuration)
./setup_corporate_env.sh
```

---

## ðŸ“‹ Manual Installation Guide

### Step 1: System Requirements

**Minimum Requirements:**
- **Python**: 3.8 or higher
- **RAM**: 8GB minimum (16GB recommended)
- **Storage**: 10GB free space
- **OS**: Windows 10/11, macOS 10.15+, or Linux

**Check Python Version:**
```bash
python3 --version
# Should show Python 3.8.x or higher
```

### Step 2: Install Ollama (AI Model Server)

Ollama is required to run the AI models locally.

**ðŸ§ Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**ðŸŽ macOS:**
```bash
# Using Homebrew
brew install ollama

# Or download from https://ollama.com
```

**ðŸªŸ Windows:**
```bash
# Download installer from https://ollama.com
# Run the installer and follow instructions
```

**Start Ollama Service:**
```bash
ollama serve
```

### Step 3: Download AI Models

Download the required AI models (this may take 10-30 minutes):

```bash
# Required models
ollama pull llama3      # Primary analysis model (4.7GB)
ollama pull mistral     # Fast error detection (4.1GB)

# Optional models
ollama pull gemma2      # Structured data analysis (5.4GB)
ollama pull codellama   # Technical transformation analysis (3.8GB)
ollama pull llama3.1    # Advanced reasoning (8.0GB)
```

**Verify models are installed:**
```bash
ollama list
```

### Step 4: Install Python Dependencies

**Create Virtual Environment (Recommended):**
```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# On Linux/macOS:
source venv/bin/activate
# On Windows:
venv\Scripts\activate
```

**Install Required Packages:**
```bash
# Install all dependencies
pip install fastapi uvicorn python-multipart python-dotenv
pip install langchain langchain-community ollama
pip install faiss-cpu sentence-transformers
pip install pypdf unstructured openpyxl python-docx
pip install pandas numpy aiofiles httpx requests pydantic

# Or install from requirements.txt (if available)
pip install -r requirements.txt
```

### Step 5: Project Setup

**Create Directory Structure:**
```bash
# Create required directories
mkdir -p rag_docs cag_docs mapping_docs static
mkdir -p rag_docs_vectorstore cag_docs_vectorstore
mkdir -p logs backups
```

**Create Environment Configuration (.env file):**
```bash
# Create .env file with corporate settings
cat > .env << EOF
# Corporate Branding Configuration
CORPORATE_APP_NAME="Professional Business Intelligence Platform"
CORPORATE_ORGANIZATION="Your Organization Name"
CORPORATE_LOGO_URL="/static/your-logo.svg"
CORPORATE_PRIMARY_COLOR="#86bc25"
CORPORATE_SECONDARY_COLOR="#0d2818"
CORPORATE_SUPPORT_EMAIL="support@yourcompany.com"

# Technical Configuration
OLLAMA_HOST=http://localhost:11434
DEFAULT_MODEL=llama3
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG=True

# Document Processing
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CONTEXT_DOCS=6
MAX_FILE_SIZE=10485760
EOF
```

---

## ðŸ–¥ï¸ Running the Application

### Start the Application

**Method 1: Direct Python**
```bash
# Ensure Ollama is running in another terminal
ollama serve

# Start the application
python main.py
```

**Method 2: Using the Startup Script**
```bash
# If you used the corporate setup
./start_corporate_analyzer.sh
```

### Access the Application

Once started, you can access:

- **ðŸ  Landing Page**: http://localhost:8000
- **ðŸ“Š Main Analyzer**: http://localhost:8000/analyzer  
- **ðŸ“š API Documentation**: http://localhost:8000/docs
- **ðŸ”§ Health Check**: http://localhost:8000/api/health

---

## ðŸ“ Project Structure

```
business-intelligence-platform/
â”œâ”€â”€ ðŸŒ Frontend
â”‚   â”œâ”€â”€ landing.html              # Corporate landing page
â”‚   â”œâ”€â”€ index.html                # Main analyzer interface
â”‚   â””â”€â”€ static/                   # Assets and logos
â”œâ”€â”€ ðŸ”§ Backend
â”‚   â”œâ”€â”€ main.py                   # FastAPI server
â”‚   â”œâ”€â”€ .env                      # Configuration file
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ rag_cag.py           # Document processing
â”‚       â””â”€â”€ data_analytics.py     # SQL analytics
â”œâ”€â”€ ðŸ“š Document Storage
â”‚   â”œâ”€â”€ rag_docs/                # Regulatory guidelines
â”‚   â”œâ”€â”€ cag_docs/                # Company procedures  
â”‚   â”œâ”€â”€ mapping_docs/            # Technical mappings
â”‚   â”œâ”€â”€ rag_docs_vectorstore/    # AI vector database
â”‚   â””â”€â”€ cag_docs_vectorstore/    # AI vector database
â”œâ”€â”€ ðŸ› ï¸ Operations
â”‚   â”œâ”€â”€ logs/                    # Application logs
â”‚   â”œâ”€â”€ backups/                 # Backup storage
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ ðŸ“– Setup Scripts
    â”œâ”€â”€ setup_corporate_env.sh    # Corporate setup
    â”œâ”€â”€ install_and_run.py        # Automated installer
    â””â”€â”€ setup_enhanced.py         # Python setup script
```

---

## ðŸŽ¯ How to Use the Platform

### 1. Upload Documents
- **RAG Documents**: Upload regulatory guidelines, compliance documents
- **CAG Documents**: Upload company procedures, internal guidelines
- **Supported formats**: PDF, TXT, MD, CSV, XLSX, DOCX

### 2. Select AI Model
- **Llama 3**: Balanced analysis for general use
- **Mistral**: Fast error detection and analysis
- **Gemma 2**: Structured data validation specialist
- **CodeLlama**: Technical transformation analysis

### 3. Configure Context
- **RAG + CAG**: Full contextual analysis (recommended)
- **RAG Only**: Regulatory focus
- **CAG Only**: Company procedure focus
- **No Context**: Direct AI analysis

### 4. Run Analysis
- Describe your mapping problem in natural language
- Get detailed analysis with actionable recommendations
- Export results for documentation

### 5. SQL Analytics (Bonus Feature)
- Upload SQLite databases
- Ask questions in natural language
- Get generated SQL queries and results

---

## ðŸŽ¨ Corporate Branding

### Customize Your Platform

**Update Logo:**
```bash
# Replace with your corporate logo
cp your-company-logo.svg static/your-logo.svg
```

**Update Colors:**
Edit the `.env` file:
```bash
CORPORATE_PRIMARY_COLOR="#YOUR_HEX_COLOR"
CORPORATE_SECONDARY_COLOR="#YOUR_HEX_COLOR"
```

**Update Organization Info:**
```bash
CORPORATE_APP_NAME="Your Platform Name"
CORPORATE_ORGANIZATION="Your Company Name"
CORPORATE_SUPPORT_EMAIL="support@yourcompany.com"
```

---

## ðŸ”§ Troubleshooting

### Common Issues and Solutions

**âŒ "Ollama not found" Error**
```bash
# Check if Ollama is installed
ollama --version

# If not installed, follow Step 2 above
# If installed but not running:
ollama serve
```

**âŒ "Model not available" Error**
```bash
# Check available models
ollama list

# Download missing models
ollama pull llama3
ollama pull mistral
```

**âŒ "Port already in use" Error**
```bash
# Check what's using port 8000
lsof -i :8000

# Kill the process or change port in .env
APP_PORT=8001
```

**âŒ Python Import Errors**
```bash
# Reinstall dependencies
pip install --upgrade -r requirements.txt

# Check virtual environment is activated
which python  # Should show venv path
```

**âŒ Vector Database Issues**
```bash
# Clear and rebuild vector databases
rm -rf rag_docs_vectorstore cag_docs_vectorstore

# Restart the application to rebuild
python main.py
```

### Log Files

Check these files for detailed error information:
- `analyzer.log` - Application logs
- `logs/startup.log` - Startup logs  
- `logs/ollama.log` - AI model logs

---

## ðŸ“Š System Monitoring

### Health Check
```bash
# Check system status
curl http://localhost:8000/api/health

# Check corporate configuration
curl http://localhost:8000/api/corporate/config
```

### Performance Optimization

**For Better Performance:**
- Use SSD storage for faster document processing
- Allocate more RAM to improve AI model performance
- Use GPU-enabled Ollama for faster inference (if available)

**Memory Usage:**
- Each AI model uses 4-8GB RAM
- Vector databases use 100-500MB per 1000 documents
- Keep 2-4GB free for document processing

---

## ðŸ”’ Security & Compliance

### Enterprise Considerations

**Audit Logging:**
- All analysis activities are logged
- User actions are tracked for compliance
- Logs available at `/api/audit/logs`

**Data Privacy:**
- All processing happens locally
- No data sent to external APIs
- Documents stored locally only

**Network Security:**
- Application runs on localhost by default
- Configure firewall rules for network access
- Use HTTPS in production environments

---

## ðŸ†˜ Support & Resources

### Getting Help

**Documentation:**
- API Documentation: http://localhost:8000/docs
- Interactive API testing available in browser

**Common Commands:**
```bash
# Check system status
python -c "import fastapi, ollama, langchain; print('âœ… All packages installed')"

# Test Ollama connection
curl http://localhost:11434/api/version

# Restart everything
pkill -f "ollama serve"
pkill -f "main.py"
ollama serve &
python main.py
```

**Community Resources:**
- [Ollama Documentation](https://ollama.com/docs)
- [LangChain Documentation](https://docs.langchain.com)
- [FastAPI Documentation](https://fastapi.tiangolo.com)

---

## ðŸ“ˆ Next Steps

### Advanced Configuration

1. **Database Integration**: Connect to PostgreSQL/MySQL for production data
2. **SSO Integration**: Add corporate authentication
3. **Monitoring**: Set up Prometheus/Grafana dashboards
4. **Scaling**: Deploy with Docker/Kubernetes for multiple users

### Feature Extensions

1. **Additional Models**: Add specialized models for your industry
2. **Custom Templates**: Create analysis templates for common scenarios  
3. **Reporting**: Build automated reporting dashboards
4. **Integration**: Connect to existing BI tools and databases

---

## âœ… Quick Verification Checklist

Before using the platform, verify:

- [ ] Python 3.8+ installed and working
- [ ] Ollama service running (`ollama serve`)
- [ ] At least one AI model downloaded (`ollama list`)
- [ ] All Python dependencies installed (`pip list`)
- [ ] Application starts without errors (`python main.py`)
- [ ] Web interface accessible (http://localhost:8000)
- [ ] Document upload works (test with sample file)
- [ ] AI analysis returns results (test with simple query)

---

**ðŸŽ‰ Congratulations! Your Business Intelligence Platform is ready for professional regulatory mapping analysis.**

For technical support or customization requests, contact your system administrator or refer to the troubleshooting section above.